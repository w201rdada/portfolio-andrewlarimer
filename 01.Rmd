---
output:
  pdf_document: default
  html_document: default
---
```{r init,include=FALSE,echo=FALSE}
readLines('https://www.zotero.org/api/users/4663483/collections/P34C3QJQ/items/top?limit=25&format=bibtex&key=EUKxuNES1nO0pWpsDWVd6mJS&v=1') %>% writeLines('references.bib')
library(magrittr)
```

# Speech2Graph {#diagramming-at-the-speed-of-speech}

#### Keywords {-}

- NLP / NLU
- Graph
- UML

## The importance of planning at brainstorming speed.

Itâ€™s common knowledge that the quality of a project is usually a direct result of the amount of planning that goes into it. Nevertheless, project creators frequently plow past critical planning steps.

One milestone that is often skipped in software development is the creation of robust UML class diagrams, which provide concrete, visual representations of how the various elements of a piece of software will divide responsibilities and interact with one another.

```{r out.height = "300px", echo=FALSE}}
knitr::include_graphics("area_diagArtboard 1.png")
```
```


![An example of a UML Class Diagram](https://www.uml-diagrams.org/examples/class-diagram-example-hasp-licensing-domain.png)

I propose to build an NLP tool that will convert the speech of a brainstorming group of developers into a clear UML class diagram. The goal is that the frictionless creation of clear, useful planning documents will enable developers to create more well-thought-out and stable products.

## A case for text to graphs for NLU

In addition to this immediate use case, this project serves as a first step towards another, longer-term goal: the creation of machine systems that can parse longer text inputs, remembering attributes of multiple parties described and understanding the developing relationships & potential dynamics between them. I believe that to develop this kind of understanding requires the conversion of text into knowledge graphs or similar structures.

UML class diagrams are a good initial target for this treatment due to their use of standard terminology (like "class", "method" and "inherits from"), their clear purpose of describing interactions between OOP classes, and their frequent use by technophiles.

## Process

The process will be based on previous work by Kumar, et al.\cite{KumarKnowledgeGraphbased2017e}

I propose to use Amazon Transcribe or Speech-to-Text-WaveNet to convert speech into text.

Amazon Lex will most likely serve as the primary chat engine, with spaCy or ParlAI helping to process incoming language. PyTorch neural networks will be deployed to identify linguistic structures (like queries vs declarative or imperative sentences). By identifying the type of sentence early on, we can abide by a CQRS (Command Query Separation) design principle, and thus appropriately treat questions differently than statements.

For flexibility in utilizing the synonyms of graphing commands, trained FastText vectors or Cortical.io semantic fingerprints will be used (so that "let's make" can trigger the same actions as "let's create" without all such terms needing to be hard coded).

Once the language has been processed, TinkerPop3 will provide the graph's knowledge storage, traversal and manipulation.

The graph will be visually rendered to the display canvas via d3, or potentially an open source UML toolkit to allow for subsequent or parallel editing via a standard GUI interface.

As the process is refined, hardware needs will need to be determined such that processing can happen in realtime.

## End goal

The primary goal of this project is to create a very fast interface for translating speech from multiple participants in a brainstorming session into a usable UML class diagram.

In addition to practical use cases on development teams, this will serve as a prototype for future spoken interfaces that can build knowledge throughout a conversation and understand how the various entities described relate to each other.