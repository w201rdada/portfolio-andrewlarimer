# Speech2Graph {#diagramming-at-the-speed-of-speech}

#### Keywords {-}

- NLP / NLU
- Graph
- UML

## The importance of planning at brainstorming speed.

The quality of the execution of a project is usually related to the level of planning that went into it, but often critical steps in the planning phase are missed. The thorough creation of easily understood, visual planning documents takes time, so many groups instead talk in generalities, with everyone affirming that they're on the same page, without having a concrete representation of exactly what's being discussed. Or for work on solo projects, a creator will have a partially baked version of a plan in his or her head, and then figure that they'll go ahead and dive into execution before they've properly diagrammed, just to get things moving. The ideas are moving more quickly than they can be diagrammed, and a frustrated creator feels like they ought to just move forward into creation.

In this project, I propose to build a tool that will convert the speech of a brainstorming group of developers into a clear UML class diagram at as close to the speed of a standard brainstorming session as possible. This will allow creators to see the brainstorming process through to its natural ending, rather than getting frustrated and moving into production prematurely. The resulting increase in planning will help developers create more well-thought-out and stable products.

## A case for text to graphs for NLU

In addition to the practical use above, this project serves as a first step towards a more longterm goal. To build machine systems that can remember, analyze information, and understand the potential dynamics in a given context, written and spoken text needs to be able to be converted into a knowledge graph. UML class diagrams' use of standard terminology (like "class", "method" and "inherits from"), clear purpose (as opposed to more general mind maps), and frequent use by technophiles all contribute towards this type of diagrams being a good beachhead graph structure to target for an initial foray into speech-to-knowledge-graph translation.

## Process

I propose to use Amazon Transcribe or Speech-to-Text-WaveNet to turn speech into text. Amazon Lex will most likely serve as the primary chat engine, with spaCy or ParlAI helping to process incoming language. PyTorch neural networks will be deployed to identify linguistic structures (like queries vs declarative or imperative sentences). For synonym flexibility, trained FastText vectors or Cortical.io semantic fingerprints will be used (so that "let's make" can trigger the same actions as "let's create" without all such terms needing to be hard coded). Once language is processed, TinkerPop3 will power the graph's knowledge storage and traversal. The graph will be visually rendered to the canvas via d3.

## Usage example

[Starting with a blank monitor in a conference room. Milo & Jill are glancing at the screen while tossing a ball back and forth.]

Milo: Should we have a "Ping-Pong Tabletop Class?"

[A rectangle is drawn with a "Ping-Pong Tabletop" label at the top. The border is a dashed line and a question mark icon in a corner identifies it as a suggestion needing confirmation, because Milo phrased it as a question.]

Jill: No. It should really be separate "Player 1 Side", "Player 2 Side", and "Net" Classes.

[Jill's starting "No" answers the system's question about the "Ping Pong Tabletop" class, and that is deleted. The subsequent classes she mentions are created.]

Milo: Okay right. And "Player 1 Side" and "Player 2 Side" can inherit from a "Player Side" class.

[A "Side" class is drawn with inheritance arrows leading to it from "Player 1 Side" and "Player 2 Side".]

Jill: Wait, what are we talking about? There should just be the "Player Side" class. Scratch "Player 1 Side" and "Player 2 Side." Those will just be instances...

["Player 1 Slide" and "Player 2 Slide" are deleted, and the conversation continues...]

## End goal

The primary goal of this project is to use the concrete, practical form of a UML class diagram. This will provide a practical use case for a prototype of a spoken interface that can handle some flexibility as it creates a knowledge graph that represents understanding of some kind of system.
